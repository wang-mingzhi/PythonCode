{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 处理深圳高精轨迹数据\n",
    "\n",
    "编码：utf-8；作者：王明智；Email：1765471602@qq.com；\n",
    "问题一：entryRoad不准确，最好根据driveangle来判断车辆从哪里进的\n",
    "问题二：同一辆车的前后时刻的trackID可能不同"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入第三方库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-02T07:50:22.068166Z",
     "start_time": "2020-10-02T07:50:14.461279Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-02T01:41:41.891579Z",
     "start_time": "2020-10-02T01:41:41.878591Z"
    }
   },
   "source": [
    "## 轨迹数据Json数据转Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-02T02:01:26.094464Z",
     "start_time": "2020-10-02T01:58:43.996805Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-02 09:58:55 merger20200313070000.txt  Done\n",
      "2020-10-02 09:59:14 merger20200313073000.txt  Done\n",
      "2020-10-02 09:59:41 merger20200313080000.txt  Done\n",
      "2020-10-02 10:00:07 merger20200313083000.txt  Done\n",
      "2020-10-02 10:00:36 merger20200313090000.txt  Done\n",
      "2020-10-02 10:01:01 merger20200313093000.txt  Done\n",
      "2020-10-02 10:01:25 merger20200313100000.txt  Done\n"
     ]
    }
   ],
   "source": [
    "def dealdata():\n",
    "    rootdir_open = r'F:\\18120900\\桌面\\毕业论文\\深圳高精\\新数据\\深圳轨迹数据\\解压后'\n",
    "    rootdir_save = r'F:\\18120900\\桌面\\毕业论文\\深圳高精\\新数据\\深圳轨迹数据\\解压后'\n",
    "    filenames = os.listdir(rootdir_open)\n",
    "    for filename in filenames:\n",
    "        path_open = os.path.join(rootdir_open, filename)\n",
    "        path_save = os.path.join(rootdir_save, filename)\n",
    "        if not os.path.isfile(path_open):\n",
    "            continue\n",
    "\n",
    "        contentlist = []\n",
    "        with open(path_open, encoding='utf-8') as f:\n",
    "            data = f.readlines()\n",
    "            json_file = [json.loads(item) for item in data]\n",
    "            title = list(json_file[0].keys())[:-1]\n",
    "            title.extend(list(json_file[0]['track'][0].keys()))\n",
    "            for items in json_file:\n",
    "                ct1 = [v for v in items.values() if not isinstance(v, list)]\n",
    "                ct2 = [list(item.values()) for item in items['track']]\n",
    "                for item in ct2:\n",
    "                    ct = ct1.copy()\n",
    "                    ct.extend(item)\n",
    "                    contentlist.append(ct)\n",
    "\n",
    "        df = pd.DataFrame(columns=title, data=contentlist)\n",
    "        df.sort_values(by='time', ascending=True, inplace=True)\n",
    "        df.drop(axis=0, columns=['track', 'vehicleYearBrand'], inplace=True)\n",
    "        df['time2'] = df['time'].apply(lambda x: datetime.fromtimestamp(x / 1000.0).strftime(\"%Y-%m-%d %H:%M:%S.%f\"))\n",
    "        df.to_csv(path_save + '.csv', index=False, encoding='utf_8_sig')\n",
    "        print(datetime.now().strftime('%Y-%m-%d %H:%M:%S'), filename, ' Done')\n",
    "\n",
    "        \n",
    "dealdata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 处理车辆轨迹数据\n",
    "\n",
    "处理思路：首先对数据按时间先后顺序排序，再遍历每一条轨迹数据，判断轨迹数据与虚拟线圈是否相交"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def isintersec(p1, p2, p3, p4):  # 判断两线段是否相交\n",
    "    # line1:(p1,p2); line2(p3,p4)\n",
    "    if max(p1[0], p2[0]) < min(p3[0], p4[0]):\n",
    "        return False\n",
    "    if max(p3[0], p4[0]) < min(p1[0], p2[0]):\n",
    "        return False\n",
    "    if max(p1[1], p2[1]) < min(p3[1], p4[1]):\n",
    "        return False\n",
    "    if max(p3[1], p4[1]) < min(p1[1], p2[1]):\n",
    "        return False\n",
    "    if np.cross(p2 - p1, p3 - p1) * np.cross(p4 - p1, p2 - p1) < 0:\n",
    "        return False\n",
    "    if np.cross(p4 - p3, p1 - p3) * np.cross(p2 - p3, p4 - p3) < 0:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def extractdata(data, result):\n",
    "    index = pd.Series(range(len(data.columns.to_list())), index=data.columns.to_list())\n",
    "    time_index, trackid_index, entryroad_index = index['time'], index['trackID'], index['entryRoad']\n",
    "    n_index, e_index = index['N'], index['E']\n",
    "\n",
    "    ptime, btime = 0, 0\n",
    "    pcars, bcars = {}, {}  # 记录前一时刻之前车辆是否经过线圈，key=(traceid,time)，value=True/False\n",
    "    data = data.sort_values(by=['time'], ascending=True).values.tolist()\n",
    "    for row in data:  # data.values比data.iterrows()快30多倍\n",
    "        # 如果前一条数据的时刻和当前数据的时刻不相同，也即是时间发生了变化\n",
    "        if ptime != row[time_index]:\n",
    "            btime, bcars = ptime, pcars\n",
    "            pcars = {}\n",
    "\n",
    "        ptime, trackid = row[time_index], row[trackid_index]\n",
    "        pcars[(trackid, ptime)] = bcars.get((trackid, btime), False)\n",
    "        temp = 0 if pcars[(trackid, ptime)] else isincoil(row[entryroad_index], row[n_index], row[e_index])\n",
    "        if temp != 0:\n",
    "            row.extend(temp[0])\n",
    "            result.append(row)\n",
    "            pcars[(trackid, ptime)] = True\n",
    "            \n",
    "            \n",
    "dealedresult = '交通量统计结果-细分结果2.xlsx'\n",
    "rootdir_open = r\"F:\\18120900\\Documents\\PythonCode\\处理深圳高精数据\\Data\"\n",
    "filenames = os.listdir(rootdir_open)\n",
    "title, result = [], []\n",
    "print(datetime.now().strftime('%Y-%m-%d %H:%M:%S'), 'Begin')\n",
    "for filename in filenames:\n",
    "    path_open = os.path.join(rootdir_open, filename)\n",
    "    data = pd.read_csv(path_open, encoding='utf-8')\n",
    "    title = data.columns.to_list() if title == [] else title\n",
    "    extractdata(data, result)\n",
    "    print(datetime.now().strftime('%Y-%m-%d %H:%M:%S'), len(data), len(result), filename)\n",
    "\n",
    "title.extend(['direction', 'entryRoad2'])\n",
    "df = pd.DataFrame(data=result, columns=title)\n",
    "df['time'] = df['time'].apply(lambda x: datetime.fromtimestamp(x / 1000.0).strftime(\"%Y-%m-%d %H:%M:%S.%f\"))\n",
    "df.to_excel(dealedresult, index=False)\n",
    "print(datetime.now().strftime('%Y-%m-%d %H:%M:%S', 'Finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 对处理结果统计分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def statisticsdata(data):\n",
    "    # 对结果进行统计\n",
    "    data['count'] = 1\n",
    "    data['time'] = pd.to_datetime(data['time'])\n",
    "    with pd.ExcelWriter(statisticsresult) as writer:\n",
    "        pivoted_data = data.pivot_table(values='count',\n",
    "                                        index='time',\n",
    "                                        columns=['entryRoad2', 'direction'],\n",
    "                                        aggfunc=np.sum)\n",
    "        dd = pivoted_data.resample('1T').sum()\n",
    "        dd.to_excel(writer, sheet_name='间隔1分钟')\n",
    "        dd = pivoted_data.resample('5T').sum()\n",
    "        dd.to_excel(writer, sheet_name='间隔5分钟')\n",
    "\n",
    "        pivoted_data2 = data.pivot_table(values='count',\n",
    "                                         index='time',\n",
    "                                         columns=['entryRoad2', 'direction', 'vehicleType'],\n",
    "                                         aggfunc=np.sum)\n",
    "        dd = pivoted_data2.resample('1T').sum()\n",
    "        dd.to_excel(writer, sheet_name='间隔1分钟-分车型')\n",
    "        dd = pivoted_data2.resample('5T').sum()\n",
    "        dd.to_excel(writer, sheet_name='间隔5分钟-分车型')\n",
    "    print(datetime.now().strftime('%Y-%m-%d %H:%M:%S'), 'Done')\n",
    "    \n",
    "    \n",
    "statisticsresult = '交通量统计结果-按时段划分2.xlsx'\n",
    "statisticsdata(pd.read_excel(dealedresult, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 展示虚拟线圈设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot(coil):\n",
    "    x, y = [], []\n",
    "    for k, v in coil.items():\n",
    "        x.extend(v[5::2])\n",
    "        y.extend(v[6::2])\n",
    "    plt.scatter(x, y)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "timelist = []\n",
    "coils = pd.read_csv(\"交叉口线圈设置.csv\", encoding='utf-8-sig')\n",
    "coils = coils.set_index('LaneID').T.to_dict()\n",
    "plot(coils)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 选取存在异常的轨迹数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-02T08:22:08.110392Z",
     "start_time": "2020-10-02T08:19:35.930382Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\18120900\\桌面\\毕业论文\\深圳高精\\ProcessedData\\Data\\merger20200313073000.txt.csv\n",
      "F:\\18120900\\桌面\\毕业论文\\深圳高精\\ProcessedData\\Data\\merger20200313080000.txt.csv\n",
      "F:\\18120900\\桌面\\毕业论文\\深圳高精\\ProcessedData\\Data\\merger20200313083000.txt.csv\n",
      "F:\\18120900\\桌面\\毕业论文\\深圳高精\\ProcessedData\\Data\\merger20200313090000.txt.csv\n",
      "F:\\18120900\\桌面\\毕业论文\\深圳高精\\ProcessedData\\Data\\merger20200313093000.txt.csv\n",
      "F:\\18120900\\桌面\\毕业论文\\深圳高精\\ProcessedData\\Data\\merger20200313100000.txt.csv\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(r\"F:\\18120900\\桌面\\处理结果-20201002.csv\", encoding='gb2312')\n",
    "selected_data = data[data['EnRoad'].isnull() & data['ExRoad'].isnull()]\n",
    "ID = selected_data['ID']\n",
    "id = [int(id.split(';')[0]) for id in ID]\n",
    "\n",
    "rootdir_open = r'F:\\18120900\\桌面\\毕业论文\\深圳高精\\ProcessedData\\Data'\n",
    "filenames = os.listdir(rootdir_open)\n",
    "result = []\n",
    "for filename in filenames:\n",
    "    if filename.endswith('csv'):\n",
    "        path_open = os.path.join(rootdir_open, filename)\n",
    "        temp = pd.read_csv(path_open)\n",
    "        selected_temp = temp[temp['trackID'].apply(lambda x:x in id)]\n",
    "        if len(result) == 0:\n",
    "            result = selected_temp\n",
    "        else:\n",
    "            result = result.append(selected_temp)\n",
    "        print(path_open)\n",
    "        \n",
    "result.to_csv(r'F:\\18120900\\桌面\\result.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "209.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
