{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 信号配时大赛\n",
    "\n",
    "作者：王明智；Email: 1765471602@qq.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入第三方库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T05:36:04.239918Z",
     "start_time": "2020-10-01T05:35:51.937011Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 修改全局参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2008-10-04T03:31:37.580588Z",
     "start_time": "2008-10-04T03:31:36.821037Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "plt.rcParams['font.sans-serif'] = ['simsun']  # 指定默认字体\n",
    "plt.rcParams['axes.unicode_minus'] = False   # 解决保存图像是负号'-'显示为方块的问题\n",
    "plt.rcParams['font.size'] = '12'              # 设置字体大小\n",
    "\n",
    "%matplotlib auto                              # 在窗体外输出图片"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 处理轨迹数据\n",
    "处理三里河东路5月30号调查获取的车辆GPS数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def dealtrackdata():\n",
    "    rootdir_open = r'.\\三里河东路5月30日GPS坐标信息'\n",
    "    filenames = os.listdir(rootdir_open)\n",
    "    data = []\n",
    "    for filename in filenames:\n",
    "        path_open = os.path.join(rootdir_open, filename)\n",
    "        if not os.path.isfile(path_open):\n",
    "            continue\n",
    "        temp_data = pd.read_csv(path_open, encoding='utf-8')\n",
    "        temp_data['description'] = filename\n",
    "        data.extend(temp_data.values)\n",
    "    df = pd.DataFrame(data=data)\n",
    "    with pd.ExcelWriter('result.xlsx') as writer:\n",
    "        df.to_excel(writer)\n",
    "        \n",
    "dealtrackdata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 合并Excel表格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combainexcels():\n",
    "    rootdir_open = r\"F:\\18120900\\桌面\\北京交通信号配时大赛\\原始数据\\五棵松周边数据\\路段数据-四环西\"\n",
    "    filenames = os.listdir(rootdir_open)\n",
    "    result = pd.DataFrame()\n",
    "    for filename in filenames:\n",
    "        path_open = os.path.join(rootdir_open, filename)\n",
    "        if not os.path.isfile(path_open):\n",
    "            continue\n",
    "        if result.empty:\n",
    "            result = pd.read_excel(path_open, 0)\n",
    "        else:\n",
    "            result = result.append(pd.read_excel(path_open, 0))\n",
    "        print(filename, result.size)\n",
    "    result.to_excel(os.path.join(rootdir_open, '路段数据汇总表-四环西.xlsx'))\n",
    "    \n",
    "combainexcels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 话路段速度变化曲线图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotsegmentdata(): \n",
    "    sheets = pd.read_excel('路段数据汇总表.xlsx', 1)\n",
    "    sheets['日期'] = sheets['日期'].apply(lambda x: datetime.datetime.strftime(x, '%m-%d'))\n",
    "    sheets['时间'] = sheets['时间'].apply(lambda x: datetime.time.strftime(x, '%H:%m'))\n",
    "\n",
    "    # 画出所有路段的速度变化曲线\n",
    "    fig, axis = plt.subplots(figsize=(5.5, 3), nrows=2, ncols=1, sharex='col')\n",
    "    plt.subplots_adjust(0.09, 0.15, 0.8, 0.93, 0.2, 0.01)\n",
    "    sns.lineplot(x='时间', y='速度', hue='路段', style='方向', data=sheets, ax=axis[0], legend=False)\n",
    "    sns.lineplot(x='时间', y='拥堵长度', hue='路段', style='方向', data=sheets, ax=axis[1])\n",
    "    plt.suptitle('各路段速度变化曲线')\n",
    "    plt.xlabel(xlabel='')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.legend(labelspacing=0.2, frameon=False, bbox_to_anchor=(1, 1), loc=6)\n",
    "    plt.show()\n",
    "\n",
    "    # 画出每条路段的速度变化曲线\n",
    "    for name, group in sheets.groupby(by='路段'):\n",
    "        fig, axis = plt.subplots(figsize=(5.5, 3), nrows=2, ncols=1, sharex='col')\n",
    "        plt.subplots_adjust(0.09, 0.15, 0.84, 0.93, 0.2, 0.01)\n",
    "        sns.lineplot(x='时间', y='速度', hue='日期', style='方向', ci=0, data=group, ax=axis[0], legend=False)\n",
    "        sns.lineplot(x='时间', y='拥堵长度', hue='日期', style='方向', ci=0, data=group, ax=axis[1])\n",
    "        plt.suptitle(name)\n",
    "        plt.xlabel(xlabel='')\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.gca().yaxis.set_major_formatter(ticker.FormatStrFormatter('%.0f'))\n",
    "        plt.legend(labelspacing=0.2, frameon=False, bbox_to_anchor=(1, 1), loc=6)\n",
    "        plt.show()\n",
    "        \n",
    "plotsegmentdata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 画车辆轨迹时空图--未完成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plottrackspacetimediagram():\n",
    "    plt.figure(figsize=(4, 3.5))\n",
    "    data = pd.read_excel('轨迹数据.xlsx', 0)\n",
    "    data['distance'] = data.apply()\n",
    "    for name, group in data.groupby(by='description'):\n",
    "        time, distance = [0], [0]\n",
    "        for row in group.sort_values(by=['time'], ascending=True).values.tolist():\n",
    "            time.append(len(time))\n",
    "            distance.append()\n",
    "        plt.plot(time, distance, 'go-')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plottrackspacetimediagram()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 画车辆轨迹图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawcartrack(sheet_index):  # 画车辆轨迹图\n",
    "    \"\"\"\n",
    "    @param sheet_index: [0] data;[1] crossroadinfo\n",
    "    @return: None\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(4, 3.5))\n",
    "    plt.subplots_adjust(0.2, 0.05, 0.98, 0.98, 0.2, 0.2)\n",
    "    data = pd.read_excel('轨迹数据.xlsx', sheet_index)\n",
    "    track, crossroad = data[sheet_index[0]], data[sheet_index[1]]\n",
    "    # 画出车辆的行驶轨迹，每条轨迹的经度调高i从而使轨迹分开\n",
    "    grouped_data, i = track.groupby(['description']), 0\n",
    "    for name, group in grouped_data:\n",
    "        plt.scatter(group.gdlongitude + i, group.gdlatitude, label=name, s=1)\n",
    "        i += 0.0003\n",
    "\n",
    "    # 画出交叉口所在位置\n",
    "    x = plt.xlim()\n",
    "    for i in range(len(crossroad)):\n",
    "        plt.plot(x, [crossroad.loc[i, 'gdlatitude'], crossroad.loc[i, 'gdlatitude']], 'k-', linewidth=1)\n",
    "\n",
    "    # 各种图表参数设置\n",
    "    plt.yticks(crossroad.gdlatitude.tolist(), crossroad.name.tolist())\n",
    "    plt.gca().xaxis.set_major_formatter(ticker.FormatStrFormatter('%.4f'))\n",
    "    plt.legend()\n",
    "\n",
    "drawcartrack([0, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 处理三里河东路交通量调查表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dealflowtable():\n",
    "    \"\"\"\n",
    "    用来\n",
    "    @return:\n",
    "    \"\"\"\n",
    "    rootdir_open = r'.\\2020年5月30日（周六）路口数据'\n",
    "    filenames = os.listdir(rootdir_open)\n",
    "    index_dict = {'路口机动车流量调查表': 0, '路口非机动车流量调查表': 1, '路口行人流量调查表': 2, '行人过街流量调查表': 3}\n",
    "    title = ['cname', 'ctype', 'cdate', 'capproach', 'time']\n",
    "    result = [[title], [title], [title], [title]]\n",
    "    for filename in filenames:\n",
    "        path_open = os.path.join(rootdir_open, filename)\n",
    "        if not os.path.isfile(path_open):\n",
    "            continue\n",
    "        sheets = pd.read_excel(path_open, sheet_name=None)  # 读取工作簿中所有excel表\n",
    "        for sheet in sheets.items():\n",
    "            tabel_index = index_dict[sheet[1].columns[0].strip()]\n",
    "            cname = sheet[1].iloc[0, 2]\n",
    "            ctype = sheet[1].iloc[1, 2]\n",
    "            cdate = sheet[1].iloc[2, 2]\n",
    "            capproach = sheet[1].iloc[3, 12] if tabel_index == 0 else ''\n",
    "\n",
    "            temp_result = {\n",
    "                0: lambda x: [x.iloc[4:46, 0:15]],\n",
    "                1: lambda x: [x.iloc[4:46, 0:9]],\n",
    "                2: lambda x: [x.iloc[4:46, 0:13]],\n",
    "                3: lambda x: [x.iloc[4:46, 0:6]]\n",
    "            }\n",
    "\n",
    "            sheet = sheet[1].apply(lambda x: x.replace('/', 0))\n",
    "            tr = temp_result[tabel_index](sheet)[0].values\n",
    "            temp_time = ''\n",
    "            for i in range(tr.shape[0]):\n",
    "                if tr[i, 0] != '' and isinstance(tr[i, 1], float) and np.isnan(tr[i, 1]):\n",
    "                    temp_time = tr[i, 0]\n",
    "                    continue\n",
    "                startcontent = [cname, ctype, cdate, capproach, temp_time]\n",
    "                startcontent.extend(tr[i, :])\n",
    "                result[tabel_index].append(startcontent)\n",
    "\n",
    "    with pd.ExcelWriter('流量调研数据处理结果.xlsx') as writer:\n",
    "        for key, value in index_dict.items():\n",
    "            df = pd.DataFrame(data=result[value])\n",
    "            df.to_excel(writer, index=False, sheet_name=key)\n",
    "\n",
    "dealflowtable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K均值聚类分析法--小时时段划分\n",
    "用来处理一天中24个小时的时段划分，可以通过肘图或轮廓图来确定聚类中心数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans(sheet, n_clusters, looptimes=5):\n",
    "    \"\"\"\n",
    "    K_Means聚类分析模型\n",
    "    @param sheet: 数据集\n",
    "    @param n_clusters: 聚类中心数\n",
    "    @param looptimes: 聚类次数\n",
    "    @return: None\n",
    "    \"\"\"\n",
    "    for name, group in sheet.groupby(['交叉口']):\n",
    "        x = group.drop(['交叉口', '时间'], axis=1).values\n",
    "        # elbowmethod(x)\n",
    "        # silhouettecoefficient(x)\n",
    "        for i in range(looptimes):\n",
    "            result = KMeans(n_clusters=n_clusters).fit(x).predict(x).tolist()\n",
    "            result.extend([name, i])\n",
    "            print(result)\n",
    "\n",
    "\n",
    "def elbowmethod(data):\n",
    "    \"\"\"\n",
    "    “肘”方法：核心指标是SSE（sum of the squared errors,误差平方和，\n",
    "    即所有样本的聚类误差（累计每个簇中样本到质心距离的平方和），随着K的增大每个簇\n",
    "    聚合度会增强，SSE下降幅度会增大，随着K值继续增大SSE的下降幅度会减少并趋于平缓\n",
    "    SSE和K值的关系图会呈现一个手肘的形状，此时肘部对应的k值就是最佳的聚类数。\n",
    "    \"\"\"\n",
    "    K = range(1, 9)  # 假设可能聚类成1-8类\n",
    "    lst = []\n",
    "    for k in K:\n",
    "        kmeans_model = KMeans(n_clusters=k).fit(data)\n",
    "        # 计算对应k值时最小值列表和的平均值\n",
    "        # cdist(data, kmeans.cluster_centers_, 'euclidean')求data到各质心\n",
    "        # cluster_centers_之间的距离平方和，'euclidean'表示使用欧式距离计算\n",
    "        dist = cdist(data, kmeans_model.cluster_centers_, 'euclidean')\n",
    "        lst.append(sum(np.min(dist, axis=1)) / data.shape[0])\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    plt.subplots_adjust(0.13, 0.12, 0.98, 0.93, 0.2, 0.2)\n",
    "    plt.plot(K, lst, 'bo-')\n",
    "    plt.title('Elbow method')\n",
    "    plt.xlabel('K')\n",
    "    plt.ylabel('Cost function')\n",
    "    plt.show()\n",
    "\n",
    "def silhouettecoefficient(data):\n",
    "    \"\"\"\n",
    "    轮廓系数法：结合聚类的凝聚度（Cohesion）和分离度（Seperation）来考虑，凝聚度为\n",
    "    样本与同簇其他样本的平均距离，分离度为样本与最近簇中所有样本的平均距离，该值处于-1到1\n",
    "    之间，值越大表示聚类效果越好。\n",
    "    \"\"\"\n",
    "    K = range(2, 9)  # 假设可能聚成2-8类\n",
    "    lst = []\n",
    "    for k in K:\n",
    "        kmeans_model = KMeans(n_clusters=k).fit(data)\n",
    "        # silhouette_score()计算所有样本的平均轮廓系数\n",
    "        # kmeans_model.labels_ 每个样本预测的类标签\n",
    "        # metric='euclidean' 使用欧式距离计算\n",
    "        sc_score = metrics.silhouette_score(data, kmeans_model.labels_, metric='euclidean')\n",
    "        lst.append(sc_score)\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    plt.subplots_adjust(0.13, 0.12, 0.98, 0.93, 0.2, 0.2)\n",
    "    plt.plot(K, lst, 'bo-')\n",
    "    plt.title('Silhouette Coefficient')\n",
    "    plt.xlabel('K')\n",
    "    plt.ylabel('Score')\n",
    "    plt.show()\n",
    "\n",
    "sheets = pd.read_excel('Data.xlsx', [0, 1, 2, 3])\n",
    "kmeans(pd.read_excel('Data.xlsx', 3), 12)\n",
    "# elbowmethod(sheets[1].values[1:])            # 画\"肘\"图来确定最好的聚类中心\n",
    "# silhouettecoefficient(sheets[1].values[1:])  # 画轮廓图来确定最好的聚类中心\n",
    "# elbowmethod(sheets[2].values[1:])            # 画”肘“图来确定最好的聚类中心\n",
    "# silhouettecoefficient(sheets[2].values[1:])  # 画轮廓图来确定最好的聚类中心"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 余弦相似性时段划分--以天为单位划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divisionoftimeperiod(data):\n",
    "    \"\"\"\n",
    "    时段划分模型\n",
    "    @param data: 数据集\n",
    "    @return: None\n",
    "    \"\"\"\n",
    "    title = data.columns.values.tolist()\n",
    "    result = []\n",
    "    # 生成21*21的矩阵(7天，每天三个纬度)，即一天与其他天的余弦值\n",
    "    for c1 in range(len(title)):\n",
    "        temp = []\n",
    "        for c2 in range(len(title)):\n",
    "            temp.append(cosine_similarity(data.iloc[:, c1], data.iloc[:, c2]))\n",
    "        result.append(temp)\n",
    "    df = pd.DataFrame(columns=title, data=result, index=title)\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    plt.subplots_adjust(0.09, 0.1, 0.98, 0.98, 0.2, 0.2)\n",
    "    sns.heatmap(df, cmap='coolwarm')\n",
    "    plt.show()\n",
    "    \n",
    "def cosine_similarity(x, y, norm=False):\n",
    "    \"\"\"\n",
    "    计算两个向量x和y的余弦相似度\n",
    "    @param x: 相量X\n",
    "    @param y: 相量Y\n",
    "    @param norm: 结果是否归一化到【0，1】区间\n",
    "    @return: double\n",
    "    \"\"\"\n",
    "    assert len(x) == len(y), \"len(x) != len(y)\"\n",
    "    if np.all(x == 0) or np.all(y == 0):\n",
    "        return float(1) if x == y else float(0)\n",
    "\n",
    "    res = np.array([[x[i] * y[i], x[i] * x[i], y[i] * y[i]] for i in range(len(x))])\n",
    "    cos = sum(res[:, 0]) / (np.sqrt(sum(res[:, 1])) * np.sqrt(sum(res[:, 2])))\n",
    "    # 归一化到[0, 1]区间内；默认不归一化\n",
    "    return 0.5 * cos + 0.5 if norm else cos\n",
    "\n",
    "ivisionoftimeperiod(pd.read_excel('Data.xlsx', 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 交通控制子区动态划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subareadivision():\n",
    "    sheets = pd.read_excel('子区划分.xlsx', [0, 1, 2])\n",
    "    # 读取交叉口的周期长度\n",
    "    cyclelengthes = sheets[0].set_index('code').T.to_dict(orient='list')\n",
    "    default_c = np.zeros(len(sorted(cyclelengthes.values())[0]))\n",
    "    # 读取相邻交叉口之间的距离\n",
    "    distances = sheets[1].set_index(['code1', 'code2']).T.to_dict(orient='list')\n",
    "    default_d = np.zeros(len(sorted(distances.values())[0]))\n",
    "    # 读取每个交叉口的流量数据\n",
    "    flows = sheets[2].set_index(['code', 'date', 'time']).T.to_dict(orient='list')\n",
    "    default_f = np.zeros(len(sorted(flows.values())[0]))\n",
    "\n",
    "    date = 20191202                # 选取哪一天的数据\n",
    "    time = 18                      # 选取一天中哪个小时的数据\n",
    "    threshold_r = 0.9              # 初始分离阈值，大于该值时划分为两个子区，迭代时该值不断递增\n",
    "    threshold_q = 0.3              # 模块度阈值，大于该值时为最优划分结果\n",
    "    q = -1                         # 模块度初始值\n",
    "    a = 2.6                        # 常数，取2.6，用来计算关联度\n",
    "    alpha1 = 0.06                  # 路段关联流量关联系数，用来计算关联度\n",
    "    alpha2 = 0.002                 # 路段长度关联系数，用来计算关联度\n",
    "    vc_min = 0.02                  # 基本通行能力乘以的系数\n",
    "    vc_max = 0.75                  # 基本通行能力乘以的系数\n",
    "    basic_traffic_capacity = 2000  # 基本通行能力\n",
    "    R_Q_dict = {}                  # key=（code1，code2）,value=(r,q)，code1 < code2\n",
    "    # distances中code2在code1的方向（NID等）在flows中对应的进口道流量的index\n",
    "    direction_dict = {'NID': 0, 'EID': 1, 'SID': 2, 'WID': 3, 'NEID': 0, 'SEID': 1, 'SWID': 2, 'NWID': 3}\n",
    "\n",
    "    # key=code;value=[小区编号，是否为独立小区, 度]\n",
    "    key = set(cyclelengthes.keys())\n",
    "    value = [[i + 1, False, 0] for i in range(len(key))]\n",
    "    result_dict = dict(zip(key, value))\n",
    "\n",
    "    # 计算每个交叉口的度，也即是每个交叉口与相邻交叉口之间的路段数\n",
    "    temp_intersectiones = [key[0] for key in distances.keys()]\n",
    "    for k, v in result_dict.items():\n",
    "        v[2] = temp_intersectiones.count(k)\n",
    "\n",
    "    # 基于向外扩张的思想，生成交通控制子区初始划分结果\n",
    "    for key, value in distances.items():\n",
    "        direction = value[0]\n",
    "        distance = value[1]\n",
    "        # 是否满足周期划分条件\n",
    "        conditions1 = abs(cyclelengthes.get(key[0], default_c)[0] - cyclelengthes.get(key[1], default_c)[0]) <= 10\n",
    "        # 是否满足流量划分条件\n",
    "        vc = flows.get((key[0], date, time), default_f)[direction_dict[direction]] / basic_traffic_capacity\n",
    "        conditions2 = (vc_min < vc < vc_max)\n",
    "        # 是否满足路段长度划分条件\n",
    "        conditions3 = distance <= 700\n",
    "        # 如果同时满足以上三个条件，则把交叉口放在同一个子区，否则划分为不同子区\n",
    "        if conditions1 and conditions2 and conditions3:\n",
    "            # 判断交叉口是否在字典里面，若不在则添加到字典里，子区编号设为key的数量+1\n",
    "            if key[0] not in result_dict:\n",
    "                result_dict[key[0]] = [len(result_dict.keys()) + 1, False, result_dict[key[0]][2]]\n",
    "            if key[1] not in result_dict:\n",
    "                result_dict[key[1]] = [len(result_dict.keys()) + 1, False, result_dict[key[0]][2]]\n",
    "\n",
    "            # 判断两个交叉口中某一个是否已经划分小区了\n",
    "            if result_dict[key[1]][1] or result_dict[key[0]][1]:\n",
    "                if result_dict[key[0]][1]:  # 若code1交叉口已经划分小区\n",
    "                    result_dict[key[1]] = [result_dict[key[0]][0], True, result_dict[key[0]][2]]\n",
    "                else:\n",
    "                    result_dict[key[0]] = [result_dict[key[1]][0], True, result_dict[key[0]][2]]\n",
    "            else:  # 若code1和code2交叉口都未划分小区\n",
    "                result_dict[key[1]] = [result_dict[key[0]][0], True, result_dict[key[0]][2]]\n",
    "                result_dict[key[0]][1] = True\n",
    "\n",
    "    # 计算所有交叉口之间的关联度\n",
    "    for i in result_dict.keys():\n",
    "        for j in result_dict.keys():\n",
    "            key = (j, i) if i > j else (i, j)\n",
    "            v = distances.get((i, j), default_d)\n",
    "            if v[0] in direction_dict.keys():\n",
    "                temp_flow = flows.get((i, date, time), default_f)[direction_dict[v[0]]]\n",
    "            else:\n",
    "                temp_flow = 0\n",
    "            R_Q_dict[key] = [1 / (1 + abs(a - alpha1 * temp_flow + alpha2 * v[1])), 0]\n",
    "\n",
    "    while q < threshold_q:\n",
    "        threshold_r += 0.01\n",
    "        # 根据交叉口关联度对初始划分方案进行调整\n",
    "        for k in R_Q_dict.keys():\n",
    "            isinonearea = (result_dict[k[0]][0] == result_dict[k[1]][0])  # 是否在一个小区\n",
    "            isgreater = (R_Q_dict[k][0] >= threshold_r)   # 关联度是否大于分离阈值时\n",
    "            if isinonearea and isgreater:\n",
    "                result_dict[k[1]][0] = max([v[0] for v in result_dict.values()]) + 1\n",
    "\n",
    "        # 计算小区的组合关联度\n",
    "        area_dict = {}\n",
    "        for key in result_dict.keys():\n",
    "            if result_dict[key][0] not in area_dict:\n",
    "                area_dict[result_dict[key][0]] = [key]\n",
    "            else:\n",
    "                area_dict[result_dict[key][0]].append(key)\n",
    "\n",
    "        # 比较小区组合关联度ra和子区边界关联度rax\n",
    "        for k in result_dict.keys():\n",
    "            for key, value in area_dict.items():\n",
    "                if calarear(value, k, R_Q_dict):\n",
    "                    result_dict[k][0] = key\n",
    "\n",
    "        # 计算划分结果的模块度\n",
    "        R_Q_dict = calq(result_dict, distances, R_Q_dict)\n",
    "        q = sum([v[1] for v in R_Q_dict.values()]) / len(distances)\n",
    "        print('模块度：' + str(q))\n",
    "\n",
    "    df = pd.DataFrame.from_dict(result_dict, orient='index')\n",
    "    with pd.ExcelWriter('子区划分结果.xlsx') as writer:\n",
    "        df.to_excel(writer)\n",
    "        \n",
    "        \n",
    "def calarear(intersectiones, intersection, r_q_dict):\n",
    "    tuple_interes = [(i, j) for i in intersectiones for j in intersectiones]\n",
    "    ra = sum([r_q_dict.get(k, [0, 0])[0] for k in tuple_interes])\n",
    "    rax = 0\n",
    "    for i in intersectiones:\n",
    "        intersection, i = (i, intersection) if i < intersection else (intersection, i)\n",
    "        rax += r_q_dict.get((intersection, i), [0, 0])[0]\n",
    "    # 需要有等于号，因为存在两个独立且不相连的交叉口\n",
    "    return ra < rax\n",
    "\n",
    "\n",
    "def calq(result_dict, distances, r_q_dict):\n",
    "    m = len(distances)  # 子区中边的个数*2\n",
    "    for key in r_q_dict.keys():\n",
    "        if result_dict[key[0]][0] != result_dict[key[1]][0]:  # 如果两个交叉口不在一个小区\n",
    "            r_q_dict[key][1] = 0\n",
    "            continue\n",
    "        if (key[0], key[1]) in distances:  # 如果两个交叉口直接相连\n",
    "            r_q_dict[key][1] = (1 - result_dict[key[0]][2] * result_dict[key[1]][2] / m)\n",
    "        else:  # 如果两个交叉口不直接相连\n",
    "            r_q_dict[key][1] = (0 - result_dict[key[0]][2] * result_dict[key[1]][2] / m)\n",
    "    return r_q_dict\n",
    "        \n",
    "subareadivision()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提取损失、延误数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extra_los_delay():\n",
    "    rootdir_open = r\"F:\\18120900\\桌面\\北京交通信号配时大赛\\交通信号配时大赛-决赛\\Synchro模型\\0-文件报告\"\n",
    "    filenames = os.listdir(rootdir_open)\n",
    "    result = []\n",
    "    for filename in filenames:\n",
    "        path_open = os.path.join(rootdir_open, filename)\n",
    "        if not os.path.isfile(path_open):\n",
    "            continue\n",
    "        print(filename)\n",
    "        with open(path_open, 'r', encoding='ANSI', errors='ignore') as f:\n",
    "            for line in f.readlines():\n",
    "                line = line.strip()\n",
    "                if line[len(line)-9::] == '2020/9/22':\n",
    "                    intersectionname = line[0:len(line)-9]\n",
    "                    result.append(filename + '\\t' + intersectionname + '\\t' + line)\n",
    "                if line[0:12] in ['Volume (vph)  ', 'Approach Del', 'Approach LOS', 'Lane Group  ']:\n",
    "                    result.append(filename + '\\t' + intersectionname + '\\t' + line)\n",
    "    f = open(os.path.join(rootdir_open, 'result2.txt'), 'w')\n",
    "    f.write('\\n'.join(result))\n",
    "    f.close()\n",
    "    \n",
    "extra_los_delay()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 画损失、延误数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T05:43:59.918340Z",
     "start_time": "2020-10-01T05:43:56.845443Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_los_delay():\n",
    "    filepath = r\"F:\\18120900\\桌面\\北京交通信号配时大赛\\交通信号配时大赛-决赛\\Synchro模型\\0-文件报告\\result2.csv\"\n",
    "    data = pd.read_csv(filepath, encoding='gb2312')\n",
    "    for name, group in data.groupby('intersection'):\n",
    "        width = 0.3  # the width of the bars\n",
    "        fig, axis = plt.subplots(figsize=(5.5, 4), nrows=3, ncols=1, sharex='col')\n",
    "        plt.subplots_adjust(0.1, 0.1, 0.98, 0.88, 0.2, 0.2)\n",
    "\n",
    "        data1 = group.loc[lambda d: d['period'] == '9.8早']\n",
    "        x = np.array(data1.loc[data1['isoptimized'] == '优化前', 'direction'])\n",
    "        label11 = data1.loc[data1['isoptimized'] == '优化前'].set_index('direction').to_dict()['los']\n",
    "        rects11 = axis[0].bar(x - width / 2, data1.loc[data1['isoptimized'] == '优化前', 'delay'], width, label='优化前')\n",
    "        label12 = data1.loc[data1['isoptimized'] == '优化后'].set_index('direction').to_dict()['los']\n",
    "        rects12 = axis[0].bar(x + width / 2, data1.loc[data1['isoptimized'] == '优化后', 'delay'], width, label='优化后')\n",
    "        axis[0].set_ylabel('延误/s')\n",
    "        axis[0].set_xlabel('早高峰')\n",
    "\n",
    "        data2 = group.loc[lambda d: d['period'] == '9.8午']\n",
    "        x = np.array(data2.loc[data2['isoptimized'] == '优化前', 'direction'])\n",
    "        label21 = data2.loc[data2['isoptimized'] == '优化前'].set_index('direction').to_dict()['los']\n",
    "        rects21 = axis[1].bar(x - width / 2, data2.loc[data2['isoptimized'] == '优化前', 'delay'], width, label='优化前')\n",
    "        label22 = data2.loc[data2['isoptimized'] == '优化后'].set_index('direction').to_dict()['los']\n",
    "        rects22 = axis[1].bar(x + width / 2, data2.loc[data2['isoptimized'] == '优化后', 'delay'], width, label='优化后')\n",
    "        axis[1].set_ylabel('延误/s')\n",
    "        axis[1].set_xlabel('午高峰')\n",
    "\n",
    "        data3 = group.loc[lambda d: d['period'] == '9.8晚']\n",
    "        x = np.array(data3.loc[data3['isoptimized'] == '优化前', 'direction'])\n",
    "        label31 = data3.loc[data3['isoptimized'] == '优化前'].set_index('direction').to_dict()['los']\n",
    "        rects31 = axis[2].bar(x - width / 2, data3.loc[data3['isoptimized'] == '优化前', 'delay'], width, label='优化前')\n",
    "        label32 = data3.loc[data3['isoptimized'] == '优化后'].set_index('direction').to_dict()['los']\n",
    "        rects32 = axis[2].bar(x + width / 2, data3.loc[data3['isoptimized'] == '优化后', 'delay'], width, label='优化后')\n",
    "        axis[2].set_ylabel('延误/s')\n",
    "        axis[2].set_xlabel('晚高峰')\n",
    "        plt.xticks([0, 1, 2, 3], ['西进口', '东进口', '南进口', '北进口'])\n",
    "\n",
    "        autolabel(rects11, axis[0], label11)\n",
    "        autolabel(rects12, axis[0], label12)\n",
    "        autolabel(rects21, axis[1], label21)\n",
    "        autolabel(rects22, axis[1], label22)\n",
    "        autolabel(rects31, axis[2], label31)\n",
    "        autolabel(rects32, axis[2], label32)\n",
    "        plt.suptitle(name)\n",
    "        plt.legend(bbox_to_anchor=(0.5, 3.3), loc=8, ncol=2, frameon=False)\n",
    "        plt.show()\n",
    "\n",
    "def autolabel(rects, ax, label):\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{0}\\n{1}'.format(height, label[int(rect.get_x() + 0.3)]),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, 0),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\", ha='center', va='bottom')\n",
    "  \n",
    "plot_los_delay() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "477px",
    "left": "1067px",
    "top": "110px",
    "width": "273.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
